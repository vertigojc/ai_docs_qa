{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in .\\.env\\lib\\site-packages (0.27.7)\n",
      "Requirement already satisfied: requests>=2.20 in .\\.env\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in .\\.env\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in .\\.env\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.env\\lib\\site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\.env\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.env\\lib\\site-packages (from requests>=2.20->openai) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\.env\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in .\\.env\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in .\\.env\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in .\\.env\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in .\\.env\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in .\\.env\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in .\\.env\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in .\\.env\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Requirement already satisfied: langchain in .\\.env\\lib\\site-packages (0.0.177)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in .\\.env\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in .\\.env\\lib\\site-packages (from langchain) (2.0.15)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in .\\.env\\lib\\site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in .\\.env\\lib\\site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in .\\.env\\lib\\site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in .\\.env\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in .\\.env\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in .\\.env\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in .\\.env\\lib\\site-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\.env\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in .\\.env\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in .\\.env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in .\\.env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in .\\.env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in .\\.env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in .\\.env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in .\\.env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in .\\.env\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in .\\.env\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in .\\.env\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in .\\.env\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\.env\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.env\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\.env\\lib\\site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in .\\.env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in .\\.env\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in .\\.env\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: unstructured in .\\.env\\lib\\site-packages (0.6.8)\n",
      "Requirement already satisfied: argilla in .\\.env\\lib\\site-packages (from unstructured) (1.7.0)\n",
      "Requirement already satisfied: lxml in .\\.env\\lib\\site-packages (from unstructured) (4.9.2)\n",
      "Requirement already satisfied: msg-parser in .\\.env\\lib\\site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: nltk in .\\.env\\lib\\site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: openpyxl in .\\.env\\lib\\site-packages (from unstructured) (3.1.2)\n",
      "Requirement already satisfied: pandas in .\\.env\\lib\\site-packages (from unstructured) (1.5.3)\n",
      "Requirement already satisfied: pdfminer.six in .\\.env\\lib\\site-packages (from unstructured) (20221105)\n",
      "Requirement already satisfied: pillow in .\\.env\\lib\\site-packages (from unstructured) (9.5.0)\n",
      "Requirement already satisfied: pypandoc in .\\.env\\lib\\site-packages (from unstructured) (1.11)\n",
      "Requirement already satisfied: python-docx in .\\.env\\lib\\site-packages (from unstructured) (0.8.11)\n",
      "Requirement already satisfied: python-pptx in .\\.env\\lib\\site-packages (from unstructured) (0.6.21)\n",
      "Requirement already satisfied: python-magic in .\\.env\\lib\\site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: markdown in .\\.env\\lib\\site-packages (from unstructured) (3.4.3)\n",
      "Requirement already satisfied: requests in .\\.env\\lib\\site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in .\\.env\\lib\\site-packages (from unstructured) (2023.5.7)\n",
      "Requirement already satisfied: httpx<0.24,>=0.15 in .\\.env\\lib\\site-packages (from argilla->unstructured) (0.23.3)\n",
      "Requirement already satisfied: deprecated~=1.2.0 in .\\.env\\lib\\site-packages (from argilla->unstructured) (1.2.13)\n",
      "Requirement already satisfied: packaging>=20.0 in .\\.env\\lib\\site-packages (from argilla->unstructured) (23.1)\n",
      "Requirement already satisfied: pydantic>=1.7.1 in .\\.env\\lib\\site-packages (from argilla->unstructured) (1.10.7)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.13 in .\\.env\\lib\\site-packages (from argilla->unstructured) (1.14.1)\n",
      "Requirement already satisfied: numpy<1.24.0 in .\\.env\\lib\\site-packages (from argilla->unstructured) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in .\\.env\\lib\\site-packages (from argilla->unstructured) (4.65.0)\n",
      "Requirement already satisfied: backoff in .\\.env\\lib\\site-packages (from argilla->unstructured) (2.2.1)\n",
      "Requirement already satisfied: monotonic in .\\.env\\lib\\site-packages (from argilla->unstructured) (1.6)\n",
      "Requirement already satisfied: rich<=13.0.1 in .\\.env\\lib\\site-packages (from argilla->unstructured) (13.0.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.6.0 in .\\.env\\lib\\site-packages (from argilla->unstructured) (0.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in .\\.env\\lib\\site-packages (from pandas->unstructured) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\.env\\lib\\site-packages (from pandas->unstructured) (2023.3)\n",
      "Requirement already satisfied: olefile>=0.46 in .\\.env\\lib\\site-packages (from msg-parser->unstructured) (0.46)\n",
      "Requirement already satisfied: click in .\\.env\\lib\\site-packages (from nltk->unstructured) (8.1.3)\n",
      "Requirement already satisfied: joblib in .\\.env\\lib\\site-packages (from nltk->unstructured) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in .\\.env\\lib\\site-packages (from nltk->unstructured) (2023.5.5)\n",
      "Requirement already satisfied: et-xmlfile in .\\.env\\lib\\site-packages (from openpyxl->unstructured) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in .\\.env\\lib\\site-packages (from pdfminer.six->unstructured) (3.1.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in .\\.env\\lib\\site-packages (from pdfminer.six->unstructured) (40.0.2)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in .\\.env\\lib\\site-packages (from python-pptx->unstructured) (3.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\.env\\lib\\site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.env\\lib\\site-packages (from requests->unstructured) (2.0.2)\n",
      "Requirement already satisfied: cffi>=1.12 in .\\.env\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in .\\.env\\lib\\site-packages (from httpx<0.24,>=0.15->argilla->unstructured) (0.16.3)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in .\\.env\\lib\\site-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.5.0)\n",
      "Requirement already satisfied: sniffio in .\\.env\\lib\\site-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in .\\.env\\lib\\site-packages (from pydantic>=1.7.1->argilla->unstructured) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in .\\.env\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->unstructured) (1.16.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in .\\.env\\lib\\site-packages (from rich<=13.0.1->argilla->unstructured) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in .\\.env\\lib\\site-packages (from rich<=13.0.1->argilla->unstructured) (2.15.1)\n",
      "Requirement already satisfied: colorama in .\\.env\\lib\\site-packages (from tqdm>=4.27.0->argilla->unstructured) (0.4.6)\n",
      "Requirement already satisfied: pycparser in .\\.env\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\.env\\lib\\site-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in .\\.env\\lib\\site-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (3.6.2)\n",
      "Requirement already satisfied: tiktoken in .\\.env\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in .\\.env\\lib\\site-packages (from tiktoken) (2023.5.5)\n",
      "Requirement already satisfied: requests>=2.26.0 in .\\.env\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\.env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\.env\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
      "Requirement already satisfied: chromadb in .\\.env\\lib\\site-packages (0.3.23)\n",
      "Requirement already satisfied: pandas>=1.3 in .\\.env\\lib\\site-packages (from chromadb) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.28 in .\\.env\\lib\\site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in .\\.env\\lib\\site-packages (from chromadb) (1.10.7)\n",
      "Requirement already satisfied: hnswlib>=0.7 in .\\.env\\lib\\site-packages (from chromadb) (0.7.0)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in .\\.env\\lib\\site-packages (from chromadb) (0.5.24)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.2 in .\\.env\\lib\\site-packages (from chromadb) (2.2.2)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in .\\.env\\lib\\site-packages (from chromadb) (0.8.0)\n",
      "Requirement already satisfied: fastapi>=0.85.1 in .\\.env\\lib\\site-packages (from chromadb) (0.95.2)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in .\\.env\\lib\\site-packages (from chromadb) (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in .\\.env\\lib\\site-packages (from chromadb) (1.23.5)\n",
      "Requirement already satisfied: posthog>=2.4.0 in .\\.env\\lib\\site-packages (from chromadb) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in .\\.env\\lib\\site-packages (from chromadb) (4.5.0)\n",
      "Requirement already satisfied: certifi in .\\.env\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.5.7)\n",
      "Requirement already satisfied: urllib3>=1.26 in .\\.env\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (2.0.2)\n",
      "Requirement already satisfied: pytz in .\\.env\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.3)\n",
      "Requirement already satisfied: zstandard in .\\.env\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0)\n",
      "Requirement already satisfied: lz4 in .\\.env\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in .\\.env\\lib\\site-packages (from fastapi>=0.85.1->chromadb) (0.27.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in .\\.env\\lib\\site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in .\\.env\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in .\\.env\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in .\\.env\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.env\\lib\\site-packages (from requests>=2.28->chromadb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\.env\\lib\\site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in .\\.env\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (4.29.2)\n",
      "Requirement already satisfied: tqdm in .\\.env\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in .\\.env\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (2.0.1)\n",
      "Requirement already satisfied: torchvision in .\\.env\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (0.15.2)\n",
      "Requirement already satisfied: scikit-learn in .\\.env\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (1.2.2)\n",
      "Requirement already satisfied: scipy in .\\.env\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (1.10.1)\n",
      "Requirement already satisfied: nltk in .\\.env\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in .\\.env\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in .\\.env\\lib\\site-packages (from sentence-transformers>=2.2.2->chromadb) (0.14.1)\n",
      "Requirement already satisfied: click>=7.0 in .\\.env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in .\\.env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: colorama>=0.4 in .\\.env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: httptools>=0.5.0 in .\\.env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in .\\.env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in .\\.env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in .\\.env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: websockets>=10.4 in .\\.env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
      "Requirement already satisfied: filelock in .\\.env\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.12.0)\n",
      "Requirement already satisfied: fsspec in .\\.env\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (2023.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in .\\.env\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (23.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in .\\.env\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (3.6.2)\n",
      "Requirement already satisfied: sympy in .\\.env\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (1.12)\n",
      "Requirement already satisfied: networkx in .\\.env\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.1)\n",
      "Requirement already satisfied: jinja2 in .\\.env\\lib\\site-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in .\\.env\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in .\\.env\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (0.13.3)\n",
      "Requirement already satisfied: joblib in .\\.env\\lib\\site-packages (from nltk->sentence-transformers>=2.2.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in .\\.env\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in .\\.env\\lib\\site-packages (from torchvision->sentence-transformers>=2.2.2->chromadb) (9.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in .\\.env\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in .\\.env\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in .\\.env\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install langchain\n",
    "!pip install unstructured\n",
    "!pip install tiktoken\n",
    "!pip install chromadb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "# Store OpenAI key in env var: OPENAI_API_KEY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we load the docs and split any that are longer than 1500 characters\n",
    "This could also be done with a different format of doc, by using a different splitter\n",
    "\n",
    "Note: Because ChatGPT can understand markdown, we are loading the docs with the raw\n",
    "`TextLoader` instead of something like the `UnstructuredMarkdownLoader` which strips\n",
    "out the markdown and leaves plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the docs\n",
    "loader = DirectoryLoader('markdown_docs/', glob=\"**/*.md\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "# Split the docs into chunks\n",
    "text_splitter = MarkdownTextSplitter(chunk_size=1500, chunk_overlap=500)\n",
    "docs = text_splitter.split_documents(docs)\n",
    "# If these markdown docs are short enough we can load full documents, otherwise we need to split them into chunks. https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/markdown.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then, we create a ChromaDB vector store with source metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: .db_storage\n"
     ]
    }
   ],
   "source": [
    "# This will create the Chroma vector database with embeddings for each chunk of text\n",
    "\n",
    "embeddings = OpenAIEmbeddings() # leave embeddings on default text-embedding-ada-002\n",
    "\n",
    "database_persistent_directory = \".db_storage\"\n",
    "vector_db = Chroma.from_texts([doc.page_content for doc in docs], embeddings, persist_directory=database_persistent_directory, metadatas=[{\"source\": f\"https://github.com/duplocloud/terraform-provider-duplocloud/blob/develop/docs/{Path(*Path(doc.metadata['source']).parts[1:]).as_posix()}\" } for doc in docs])\n",
    "\n",
    "vector_db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: .db_storage\n"
     ]
    }
   ],
   "source": [
    "# If changes have been persisted already, we can load from local storage instead of re-creating the database\n",
    "database_persistent_directory = \".db_storage\"\n",
    "\n",
    "vector_db = Chroma(persist_directory=database_persistent_directory, embedding_function=embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Functions\n",
    "\n",
    "Some custom functions to make interacting with the OpenAI API easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def get_response(question: str, history: List[Dict[str, str]], model: str=\"gpt-3.5-turbo\", temperature: float=0.5, stream: bool=True, timeout=None):\n",
    "    if not timeout:\n",
    "        timeout = 2.0 if stream else 60.0\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model= model,\n",
    "        messages= history + [\n",
    "            {'role': 'user', 'content': f\"{question}\"},\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        stream=stream,\n",
    "        request_timeout=timeout\n",
    "    )\n",
    "\n",
    "    LINE_LENGTH = 80\n",
    "    this_line_length = 0\n",
    "    full_response = \"\"\n",
    "    if not stream:\n",
    "        response = [{\"choices\": [{\"delta\": {\"content\": f\"{chunk} \"}}]} for chunk in response[\"choices\"][0][\"message\"][\"content\"].split(\" \")]\n",
    "    for chunk in response:\n",
    "        chunk_text = chunk[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
    "        full_response += chunk_text\n",
    "\n",
    "        if \"\\n\" in chunk_text:\n",
    "            parts = chunk_text.split(\"\\n\")\n",
    "            for part in parts[:-1]:\n",
    "                print(f\"{part}\\n\", end='', flush=True)\n",
    "            this_line_length = 0\n",
    "            chunk_text = parts[-1]\n",
    "        if this_line_length + len(chunk_text) > LINE_LENGTH:\n",
    "            first_char = chunk_text[:1] if chunk_text[:1] in (\" \", \".\", \"!\", \"?\", \",\", \";\", \":\") else \"\"\n",
    "            print(f\"{first_char}\", end='\\n', flush=True)\n",
    "            chunk_text = chunk_text[len(first_char):]\n",
    "            this_line_length = 0\n",
    "        this_line_length += len(chunk_text)\n",
    "        print(f\"{chunk_text}\", end='', flush=True)\n",
    "    return full_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Heading 1\n",
      "## Heading 2\n",
      "### Heading 3\n",
      "\n",
      "*Italic*\n",
      "**Bold**\n",
      "***Bold and Italic***\n",
      "\n",
      "- List item 1\n",
      "- List item 2\n",
      "- List item 3\n",
      "\n",
      "[Link](https://www.example.com)\n",
      "\n",
      "> Blockquote\n",
      "\n",
      "`Inline code`\n",
      "\n",
      "```\n",
      "Code block\n",
      "```"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Heading 1\n",
       "## Heading 2\n",
       "### Heading 3\n",
       "\n",
       "*Italic*\n",
       "**Bold**\n",
       "***Bold and Italic***\n",
       "\n",
       "- List item 1\n",
       "- List item 2\n",
       "- List item 3\n",
       "\n",
       "[Link](https://www.example.com)\n",
       "\n",
       "> Blockquote\n",
       "\n",
       "`Inline code`\n",
       "\n",
       "```\n",
       "Code block\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = get_response(\"Give an example of some basic Markdown syntax, using Markdown for formatting.\", [], model=\"gpt-3.5-turbo\", temperature=0.5, stream=True)\n",
    "\n",
    "display(Markdown(res)) # This will display the markdown formatting in the Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_in_text(text):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\") # This is encoding for the chat models\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from OpenAI to get the number of tokens used by a list of messages\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model == \"gpt-3.5-turbo\":\n",
    "        print(\"Warning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\")\n",
    "    elif model == \"gpt-4\":\n",
    "        print(\"Warning: gpt-4 may change over time. Returning num tokens assuming gpt-4-0314.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0314\")\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif model == \"gpt-4-0314\":\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    else:\n",
    "        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Lookup Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This returns the top k most similar documents to the query\n",
    "\n",
    "doc_lookup = vector_db.similarity_search(query=\"Does Duplocloud have a terraform provider?\", k=4)\n",
    "for doc in doc_lookup:\n",
    "    print(f\"{doc.metadata['source']}\")\n",
    "    display(Markdown(doc.page_content))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the MMR function returns the top k most similar documents to the query, but with a diversity penalty to avoid returning documents that are too similar to each other\n",
    "\n",
    "doc_lookup_mmr = vector_db.max_marginal_relevance_search(query=\"How do I initialize a the duplocloud terraform provider?\", k=4)\n",
    "for doc in doc_lookup_mmr:\n",
    "    print(f\"{doc.metadata['source']}\")\n",
    "    display(Markdown(doc.page_content))\n",
    "    print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMPLATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_document_list(documents: List[Document], max_tokens = 1000):\n",
    "    template = \"----------------------------------------\\nDocument {index}: {source}\\n{doc.page_content}\\n\\n\"\n",
    "    total_tokens = 0\n",
    "    result = \"\"\n",
    "    for index, doc in enumerate(documents):\n",
    "        doc_text = template.format(index=index+1, source=doc.metadata[\"source\"], doc=doc)\n",
    "        total_tokens += num_tokens_in_text(doc_text)\n",
    "        if total_tokens > max_tokens:\n",
    "            break\n",
    "        result += doc_text\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Asking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_from_sources(question):\n",
    "    doc_lookup = vector_db.max_marginal_relevance_search(query=question, k=4)\n",
    "    documents = create_document_list(doc_lookup, max_tokens=1000)\n",
    "    prompt = f\"Please use the following documents as well as your existing knowledge to answer this question: {question}\\n\\n\" + documents\n",
    "    print(\"Generating answer using the following documents:\\n\" + \"\\n\".join([f\"{doc.metadata['source']}\" for doc in doc_lookup]))\n",
    "    response = get_response(prompt, [], model=\"gpt-3.5-turbo\", temperature=0.5, stream=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating answer using the following documents:\n",
      "https://github.com/duplocloud/terraform-provider-duplocloud/blob/develop/docs/resources/k8_ingress.md\n",
      "https://github.com/duplocloud/terraform-provider-duplocloud/blob/develop/docs/resources/aws_cloudfront_distribution.md\n",
      "https://github.com/duplocloud/terraform-provider-duplocloud/blob/develop/docs/resources/azure_virtual_machine_scale_set.md\n",
      "https://github.com/duplocloud/terraform-provider-duplocloud/blob/develop/docs/resources/other_agents.md\n",
      "Example .tf file for Duplocloud Terraform Provider:\n",
      "\n",
      "```terraform\n",
      "provider \"duplocloud\" {\n",
      "  # add your provider configuration here\n",
      "}\n",
      "\n",
      "resource \"duplocloud_duplo_service\" \"example_service\" {\n",
      "  tenant_id = \"your_tenant_id\"\n",
      "  name = \"example_service\"\n",
      "  replicas = 2\n",
      "  lb_synced_deployment = true\n",
      "  cloud_creds_from_k8s_service_account = false\n",
      "  is_daemonset = false\n",
      "  agent_platform = 7\n",
      "  cloud = 0\n",
      "  docker_image = \"nginx:latest\"\n",
      "}\n",
      "\n",
      "resource \"duplocloud_duplo_service_lbconfigs\" \"example_service_lb\" {\n",
      "  tenant_id = duplocloud_duplo_service.example_service.tenant_id\n",
      "  replication_controller_name = duplocloud_duplo_service.example_service.name\n",
      "  lbconfigs {\n",
      "    lb_type = 4\n",
      "    is_native = false\n",
      "    is_internal = false\n",
      "    port = 80\n",
      "    external_port = 8080\n",
      "    protocol = \"tcp\"\n",
      "    health_check_url = \"/\"\n",
      "  }\n",
      "}\n",
      "\n",
      "resource \"duplocloud_aws_cloudfront_distribution\" \"example_cdn\" {\n",
      "  tenant_id = \"your_tenant_id\"\n",
      "  comment = \"example_cdn\"\n",
      "  default_root_object = \"index.html\"\n",
      "  enabled = true\n",
      "  http_version = \"http2\"\n",
      "  is_ipv6_enabled = true\n",
      "  aliases = [\"example.com\"]\n",
      "  price_class = \"PriceClass_All\"\n",
      "  wait_for_deployment = true\n",
      "\n",
      "  origin {\n",
      "    domain_name = \"example-origin.com\"\n",
      "    origin_id = \"example-origin.com\"\n",
      "    connection_attempts = 3\n",
      "    connection_timeout = 10\n",
      "    custom_origin_config {\n",
      "      http_port = 80\n",
      "      https_port = 443\n",
      "      origin_keepalive_timeout = 30\n",
      "      origin_read_timeout = 30\n",
      "      origin_protocol_policy = \"https-only\"\n",
      "      origin_ssl_protocols = [\"TLSv1.2\"]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "``` \n",
      "\n",
      "Note: Replace \"your_tenant_id\" and other values with appropriate values for your \n",
      "use case."
     ]
    }
   ],
   "source": [
    "res = question_from_sources(\"Please write a short example .tf file for the Duplocloud terraform provider.\")\n",
    "display(Markdown(res))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
